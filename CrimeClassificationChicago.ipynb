{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to execute python and spark commands and libraries\n",
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"clipper-pyspark\").getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries to perform visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "np.random.seed(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Structure\n",
      "----------------------------------\n",
      "root\n",
      " |-- Primary Type: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n",
      "None\n",
      " \n",
      "Dataframe preview\n",
      "+-------------------+--------------------+\n",
      "|       Primary Type|         Description|\n",
      "+-------------------+--------------------+\n",
      "| deceptive practice|financial identit...|\n",
      "|crim sexual assault|      non-aggravated|\n",
      "|           burglary|      unlawful entry|\n",
      "|              theft|           over $500|\n",
      "|crim sexual assault|      non-aggravated|\n",
      "+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      " \n",
      "----------------------------------\n",
      "Total number of rows 7032560\n"
     ]
    }
   ],
   "source": [
    "#Read the data into spark datafrome\n",
    "from pyspark.sql.functions import col, lower\n",
    "df = spark.read.csv('/Users/manje/Documents/MANJEERA/SEM 2/BIG DATA ANALYTICS/TECHNIAL PROJECT/output_file_final.csv', inferSchema=True, header=True)\n",
    "\n",
    "data = df.select(lower(col('Primary Type')),lower(col('Description')))\\\n",
    "        .withColumnRenamed('lower(Primary Type)','Primary Type')\\\n",
    "        .withColumnRenamed('lower(Description)', 'Description')\n",
    "data.cache()\n",
    "print('Dataframe Structure')\n",
    "print('----------------------------------')\n",
    "print(data.printSchema())\n",
    "print(' ')\n",
    "print('Dataframe preview')\n",
    "print(data.show(5))\n",
    "print(' ')\n",
    "print('----------------------------------')\n",
    "print('Total number of rows', df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique value of Primary Type: 35\n",
      " \n",
      "Top 10 Crime Primary Type\n",
      "+-------------------+----------+\n",
      "|       Primary Type|totalValue|\n",
      "+-------------------+----------+\n",
      "|              theft|   1486432|\n",
      "|            battery|   1285561|\n",
      "|    criminal damage|    800484|\n",
      "|          narcotics|    726658|\n",
      "|            assault|    440824|\n",
      "|      other offense|    436869|\n",
      "|           burglary|    398672|\n",
      "|motor vehicle theft|    324105|\n",
      "| deceptive practice|    284366|\n",
      "|            robbery|    264485|\n",
      "+-------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      " \n",
      " \n",
      "Total number of unique value of Description: 381\n",
      " \n",
      "Top 10 Crime Description\n",
      "+--------------------+----------+\n",
      "|         Description|totalValue|\n",
      "+--------------------+----------+\n",
      "|              simple|    829104|\n",
      "|      $500 and under|    572188|\n",
      "|domestic battery ...|    542802|\n",
      "|          to vehicle|    388870|\n",
      "|         to property|    368875|\n",
      "|           over $500|    364510|\n",
      "|poss: cannabis 30...|    278021|\n",
      "|      forcible entry|    269153|\n",
      "|          automobile|    254900|\n",
      "|       from building|    238499|\n",
      "+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Defining the top categories of crime with the highest total count\n",
    "def top_n_list(df,var, N):\n",
    "    '''\n",
    "    This function determine the top N numbers of the list \n",
    "    '''\n",
    "    print(\"Total number of unique value of\"+' '+var+''+':'+' '+str(df.select(var).distinct().count()))\n",
    "    print(' ')\n",
    "    print('Top'+' '+str(N)+' '+'Crime'+' '+var)\n",
    "    df.groupBy(var).count().withColumnRenamed('count','totalValue')\\\n",
    "    .orderBy(col('totalValue').desc()).show(N)\n",
    "    \n",
    "    \n",
    "top_n_list(data, 'Primary Type',10)\n",
    "print(' ')\n",
    "print(' ')\n",
    "top_n_list(data,'Description',10)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the distinct crime count based on the type of crime\n",
    "data.select('Primary Type').distinct().count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are splitting the input data into Training set and Test set randomly in order to train and test the model respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 4924319\n",
      "Test Dataset Count: 2108241\n"
     ]
    }
   ],
   "source": [
    "training, test = data.randomSplit([0.7,0.3], seed=60)\n",
    "#trainingSet.cache()\n",
    "print(\"Training Dataset Count:\", training.count())\n",
    "print(\"Test Dataset Count:\", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is to import the various text classification libraries and to create a pipeline for the features extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, OneHotEncoder, StringIndexer, VectorAssembler, HashingTF, IDF, Word2Vec\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes \n",
    "\n",
    "#Defining the tokenizer using regextokenizer function\n",
    "regex_tokenizer = RegexTokenizer(pattern='\\\\W')\\\n",
    "                  .setInputCol(\"Description\")\\\n",
    "                  .setOutputCol(\"tokens\")\n",
    "\n",
    "#Defining the stopwords using stopwordsremover function\n",
    "extra_stopwords = ['http','amp','rt','t','c','the']\n",
    "stopwords_remover = StopWordsRemover()\\\n",
    "                    .setInputCol('tokens')\\\n",
    "                    .setOutputCol('filtered_words')\\\n",
    "                    .setStopWords(extra_stopwords)\n",
    "                    \n",
    "\n",
    "#Defining a set of words using countVectorizer function\n",
    "count_vectors = CountVectorizer(vocabSize=10000, minDF=5)\\\n",
    "               .setInputCol(\"filtered_words\")\\\n",
    "               .setOutputCol(\"features\")\n",
    "\n",
    "\n",
    "#Defining TF-IDF to vectorise features \n",
    "hashingTf = HashingTF(numFeatures=10000)\\\n",
    "            .setInputCol(\"filtered_words\")\\\n",
    "            .setOutputCol(\"raw_features\")\n",
    "            \n",
    "#Using minDocFreq to remove sparse terms\n",
    "idf = IDF(minDocFreq=5)\\\n",
    "        .setInputCol(\"raw_features\")\\\n",
    "        .setOutputCol(\"features\")\n",
    "\n",
    "#Encoding the Category variable into label using StringIndexer\n",
    "label_string_idx = StringIndexer()\\\n",
    "                  .setInputCol(\"Primary Type\")\\\n",
    "                  .setOutputCol(\"label\")\n",
    "\n",
    "#Defining classifier structure for logistic Regression imported from the library\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "#Defining classifier structure for Naive Bayes\n",
    "nb = NaiveBayes(smoothing=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model using logistic regression by converting features into count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model using Logistic Regression after converting the features into vectors\n",
    "pipeline_cv_lr = Pipeline().setStages([regex_tokenizer,stopwords_remover,count_vectors,label_string_idx, lr])\n",
    "model_cv_lr = pipeline_cv_lr.fit(training)\n",
    "predictions_cv_lr = model_cv_lr.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the TOP Predictions\n",
      "+---------------------------+------------+------------------------------+-----+----------+\n",
      "|                Description|Primary Type|                   probability|label|prediction|\n",
      "+---------------------------+------------+------------------------------+-----+----------+\n",
      "|from coin-op machine/device|       theft|[0.8425360622808422,0.02801...|  0.0|       0.0|\n",
      "|from coin-op machine/device|       theft|[0.8425360622808422,0.02801...|  0.0|       0.0|\n",
      "|from coin-op machine/device|       theft|[0.8425360622808422,0.02801...|  0.0|       0.0|\n",
      "|from coin-op machine/device|       theft|[0.8425360622808422,0.02801...|  0.0|       0.0|\n",
      "|from coin-op machine/device|       theft|[0.8425360622808422,0.02801...|  0.0|       0.0|\n",
      "+---------------------------+------------+------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displaying the top predictions of the model\n",
    "print('Displaying the TOP Predictions')\n",
    "predictions_cv_lr.select('Description','Primary Type',\"probability\",\"label\",\"prediction\")\\\n",
    "                                        .orderBy(\"probability\", ascending=False)\\\n",
    "                                        .show(n=5, truncate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model\n",
      "accuracy:89.0%\n"
     ]
    }
   ],
   "source": [
    "#Determing the accuracy of the model\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator \n",
    "evaluator_cv_lr = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_cv_lr)\n",
    "print('Accuracy of the model')\n",
    "print('accuracy:{}%'.format(np.round(evaluator_cv_lr,2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Secondary model using NaiveBayes\n",
    "pipeline_cv_nb = Pipeline().setStages([regex_tokenizer,stopwords_remover,count_vectors,label_string_idx, nb])\n",
    "model_cv_nb = pipeline_cv_nb.fit(training)\n",
    "predictions_cv_nb = model_cv_nb.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model\n",
      "accuracy:92.0%\n"
     ]
    }
   ],
   "source": [
    "# Evaluting the accuracy of the model and displaying the accuracy\n",
    "evaluator_cv_nb = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_cv_nb)\n",
    "print('Accuracy of the model')\n",
    "print('accuracy:{}%'.format(np.round(evaluator_cv_nb,2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model using Logistic regression with the help of TF-IDF\n",
    "pipeline_idf_lr = Pipeline().setStages([regex_tokenizer,stopwords_remover,hashingTf, idf, label_string_idx, lr])\n",
    "model_idf_lr = pipeline_idf_lr.fit(training)\n",
    "predictions_idf_lr = model_idf_lr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few predictions of the model\n",
      " \n",
      "+---------------------------+------------+------------------------------+-----+----------+\n",
      "|                Description|Primary Type|                   probability|label|prediction|\n",
      "+---------------------------+------------+------------------------------+-----+----------+\n",
      "|from coin-op machine/device|       theft|[0.8424143819961089,0.02800...|  0.0|       0.0|\n",
      "|from coin-op machine/device|       theft|[0.8424143819961089,0.02800...|  0.0|       0.0|\n",
      "|from coin-op machine/device|       theft|[0.8424143819961089,0.02800...|  0.0|       0.0|\n",
      "|from coin-op machine/device|       theft|[0.8424143819961089,0.02800...|  0.0|       0.0|\n",
      "|from coin-op machine/device|       theft|[0.8424143819961089,0.02800...|  0.0|       0.0|\n",
      "+---------------------------+------------+------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displaying the top predictions of the model\n",
    "print('Few predictions of the model')\n",
    "print(' ')\n",
    "predictions_idf_lr.select('Description','Primary Type',\"probability\",\"label\",\"prediction\")\\\n",
    "                                        .orderBy(\"probability\", ascending=False)\\\n",
    "                                        .show(n=5, truncate=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model\n",
      "accuracy:89.0%\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model and displaying the accuracy of the model using test data\n",
    "evaluator_idf_lr = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_idf_lr)\n",
    "print('Accuracy of the model')\n",
    "print('accuracy:{}%'.format(np.round(evaluator_idf_lr,2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model using Naive Bayes algorithm using the TF-IDF function\n",
    "pipeline_idf_nb = Pipeline().setStages([regex_tokenizer,stopwords_remover,hashingTf, idf, label_string_idx, nb])\n",
    "model_idf_nb = pipeline_idf_nb.fit(training)\n",
    "predictions_idf_nb = model_idf_nb.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model\n",
      "accuracy:92.0%\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model and displaying the accuracy of the model\n",
    "evaluator_idf_nb = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_idf_nb)\n",
    "print('Accuracy of the model')\n",
    "print('accuracy:{}%'.format(np.round(evaluator_idf_nb,2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
